{"cells": [{"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["%%writefile code/inference.py\n", "import os\n", "import torch\n", "from diffusers import DiffusionPipeline, DPMSolverMultistepScheduler\n", "from compel import Compel, ReturnedEmbeddingsType\n", "import json\n", "import base64\n", "from io import BytesIO\n", "import asyncio\n", "import subprocess\n", "import boto3\n", "\n", "def model_fn(model_dir):\n", "    base_path = os.path.join(model_dir, 'base')\n", "    refiner_path = os.path.join(model_dir, 'refiner')\n", "    lora_path = os.path.join(model_dir, 'Trained_lora')\n", "\n", "    base = DiffusionPipeline.from_pretrained(\n", "        base_path,\n", "        torch_dtype=torch.float16,\n", "        variant=\"fp16\",\n", "        use_safetensors=True,\n", "    ).to(\"cuda\")\n", "    \n", "    base.load_lora_weights(\n", "        lora_path,\n", "        weight_name=\"pytorch_lora_weights.safetensors\"\n", "    )\n", "    \n", "    refiner = DiffusionPipeline.from_pretrained(\n", "        refiner_path,\n", "        text_encoder_2=base.text_encoder_2,\n", "        vae=base.vae,\n", "        torch_dtype=torch.float16,\n", "        use_safetensors=True,\n", "        variant=\"fp16\",\n", "    ).to(\"cuda\")\n", "\n", "    compel = Compel(\n", "        tokenizer=[base.tokenizer, base.tokenizer_2],\n", "        text_encoder=[base.text_encoder, base.text_encoder_2],\n", "        returned_embeddings_type=ReturnedEmbeddingsType.PENULTIMATE_HIDDEN_STATES_NON_NORMALIZED,\n", "        requires_pooled=[False, True])\n", "\n", "    compel_refiner = Compel(\n", "        tokenizer=[refiner.tokenizer_2],\n", "        text_encoder=[refiner.text_encoder_2],\n", "        returned_embeddings_type=ReturnedEmbeddingsType.PENULTIMATE_HIDDEN_STATES_NON_NORMALIZED,\n", "        requires_pooled=[True],\n", "    )\n", "\n", "    return base, refiner, compel, compel_refiner\n", "\n", "def predict_fn(data, models):\n", "    if data.get(\"action\") == \"train\":\n", "        loop = asyncio.get_event_loop()\n", "        return loop.run_until_complete(train_model(\n", "            data[\"collection_s3_path\"],\n", "            data[\"prompt\"],\n", "            data[\"output_dir_name\"]\n", "        ))\n", "    else:\n", "        base, refiner, compel, compel_refiner = models\n", "        prompt = data.pop(\"prompt\", \"\")\n", "        negative_prompt = data.pop(\"negative_prompt\", \"\")\n", "\n", "        conditioning, pooled = compel(prompt)\n", "        negative_conditioning, negative_pooled = compel(negative_prompt)\n", "        conditioning_refiner, pooled_refiner = compel_refiner(prompt)\n", "        negative_conditioning_refiner, negative_pooled_refiner = compel_refiner(negative_prompt)\n", "\n", "        image = base(\n", "            prompt_embeds=conditioning,\n", "            pooled_prompt_embeds=pooled,\n", "            negative_prompt_embeds=negative_conditioning,\n", "            negative_pooled_prompt_embeds=negative_pooled,\n", "            num_inference_steps=40,\n", "            denoising_end=0.8,\n", "            output_type=\"latent\",\n", "        ).images[0]\n", "\n", "        refiner_result = refiner(\n", "            prompt_embeds=conditioning_refiner,\n", "            pooled_prompt_embeds=pooled_refiner,\n", "            negative_prompt_embeds=negative_conditioning_refiner,\n", "            negative_pooled_prompt_embeds=negative_pooled_refiner,\n", "            num_inference_steps=40,\n", "            denoising_start=0.8,\n", "            image=image,\n", "        ).images[0]\n", "\n", "        buffered = BytesIO()\n", "        refiner_result.save(buffered, format=\"PNG\")\n", "        img_str = base64.b64encode(buffered.getvalue()).decode()\n", "\n", "        return {'image': img_str}\n"]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.8.0"}}, "nbformat": 4, "nbformat_minor": 4}