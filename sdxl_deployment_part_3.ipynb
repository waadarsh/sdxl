{"cells": [{"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["async def train_model(collection_s3_path, prompt, output_dir_name):\n", "    s3 = boto3.resource('s3')\n", "    collection_bucket, collection_key = parse_s3_uri(collection_s3_path)\n", "    \n", "    local_collection_path = '/tmp/training_data'\n", "    download_from_s3(s3, collection_bucket, collection_key, local_collection_path)\n", "    \n", "    output_s3_path = f\"s3://{collection_bucket}/model_outputs/{output_dir_name}\"\n", "    \n", "    command = f\"\"\"\n", "    accelerate launch train_dreambooth_lora_sdxl.py \\\n", "      --pretrained_model_name_or_path='/opt/ml/model/base'  \\\n", "      --instance_data_dir='{local_collection_path}' \\\n", "      --pretrained_vae_model_name_or_path=\"madebyollin/sdxl-vae-fp16-fix\" \\\n", "      --output_dir=\"/tmp/trained_model\" \\\n", "      --mixed_precision=\"fp16\" \\\n", "      --instance_prompt=\"{prompt}\" \\\n", "      --resolution=1024 \\\n", "      --train_batch_size=2 \\\n", "      --gradient_accumulation_steps=2 \\\n", "      --gradient_checkpointing \\\n", "      --learning_rate=1e-4 \\\n", "      --lr_scheduler=\"constant\" \\\n", "      --lr_warmup_steps=0 \\\n", "      --max_train_steps=500 \\\n", "      --seed=\"0\"\n", "    \"\"\"\n", "    \n", "    process = await asyncio.create_subprocess_shell(\n", "        command,\n", "        stdout=asyncio.subprocess.PIPE,\n", "        stderr=asyncio.subprocess.PIPE\n", "    )\n", "    stdout, stderr = await process.communicate()\n", "    \n", "    if process.returncode == 0:\n", "        upload_to_s3(s3, '/tmp/trained_model', collection_bucket, f\"model_outputs/{output_dir_name}\")\n", "        return {\"status\": \"success\", \"output_s3_path\": output_s3_path}\n", "    else:\n", "        return {\"status\": \"failed\", \"error\": stderr.decode()}\n", "\n", "def parse_s3_uri(uri):\n", "    parts = uri.replace(\"s3://\", \"\").split(\"/\")\n", "    bucket = parts.pop(0)\n", "    key = \"/\".join(parts)\n", "    return bucket, key\n", "\n", "def download_from_s3(s3, bucket, key, local_path):\n", "    os.makedirs(local_path, exist_ok=True)\n", "    for obj in s3.Bucket(bucket).objects.filter(Prefix=key):\n", "        if not obj.key.endswith('/'):\n", "            target = os.path.join(local_path, os.path.relpath(obj.key, key))\n", "            if not os.path.exists(os.path.dirname(target)):\n", "                os.makedirs(os.path.dirname(target))\n", "            s3.Bucket(bucket).download_file(obj.key, target)\n", "\n", "def upload_to_s3(s3, local_dir, bucket, s3_path):\n", "    for root, _, files in os.walk(local_dir):\n", "        for file in files:\n", "            local_file = os.path.join(root, file)\n", "            relative_path = os.path.relpath(local_file, local_dir)\n", "            s3_file = os.path.join(s3_path, relative_path)\n", "            s3.Bucket(bucket).upload_file(local_file, s3_file)\n", "        return True"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## 3. Download and Prepare the Model"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from distutils.dir_util import copy_tree\n", "from pathlib import Path\n", "from huggingface_hub import snapshot_download\n", "import random\n", "import os\n", "\n", "# Set up model IDs and tokens\n", "BASE_MODEL_ID = \"stabilityai/stable-diffusion-xl-base-1.0\"\n", "REFINER_MODEL_ID = \"stabilityai/stable-diffusion-xl-refiner-1.0\"\n", "HF_TOKEN = os.environ.get('HF_TOKEN')\n", "assert len(HF_TOKEN) > 0, \"Please set HF_TOKEN to your huggingface token.\"\n", "\n", "# Create a unique directory for the model\n", "model_tar = Path(f\"model-{random.getrandbits(16)}\")\n", "model_tar.mkdir(exist_ok=True)\n", "\n", "# Download and copy base model\n", "print(\"Downloading base model...\")\n", "base_snapshot_dir = snapshot_download(repo_id=BASE_MODEL_ID, revision=\"main\", use_auth_token=HF_TOKEN)\n", "base_model_dir = model_tar / \"base\"\n", "base_model_dir.mkdir(exist_ok=True)\n", "copy_tree(base_snapshot_dir, str(base_model_dir))\n", "\n", "# Download and copy refiner model\n", "print(\"Downloading refiner model...\")\n", "refiner_snapshot_dir = snapshot_download(repo_id=REFINER_MODEL_ID, revision=\"main\", use_auth_token=HF_TOKEN)\n", "refiner_model_dir = model_tar / \"refiner\"\n", "refiner_model_dir.mkdir(exist_ok=True)\n", "copy_tree(refiner_snapshot_dir, str(refiner_model_dir))\n", "\n", "# Create a directory for LoRA weights (assuming you have them)\n", "lora_dir = model_tar / \"Trained_lora\"\n", "lora_dir.mkdir(exist_ok=True)\n", "# If you have LoRA weights, uncomment and modify the following line:\n", "# copy_tree(\"path/to/your/lora/weights\", str(lora_dir))\n", "\n", "# Copy the code directory\n", "code_dir = model_tar / \"code\"\n", "code_dir.mkdir(exist_ok=True)\n", "copy_tree(\"code/\", str(code_dir))\n", "\n", "print(f\"Model files prepared in directory: {model_tar}\")"]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.8.0"}}, "nbformat": 4, "nbformat_minor": 4}