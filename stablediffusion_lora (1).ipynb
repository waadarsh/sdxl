{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8314fc9b-c468-497b-abcc-259ec792154c",
      "metadata": {
        "tags": [],
        "id": "8314fc9b-c468-497b-abcc-259ec792154c"
      },
      "outputs": [],
      "source": [
        "import sagemaker\n",
        "import boto3\n",
        "from sagemaker.pytorch import PyTorch\n",
        "sagemaker_session = sagemaker.Session()\n",
        "bucket = sagemaker_session.default_bucket()\n",
        "role = sagemaker.get_execution_role()\n",
        "account_id = boto3.client('sts').get_caller_identity().get('Account')\n",
        "region_name = boto3.session.Session().region_name\n",
        "images_s3uri = 's3://{0}/lora/images/'.format(bucket)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3656f142-057c-4bc9-bd38-ea318b8c4865",
      "metadata": {
        "id": "3656f142-057c-4bc9-bd38-ea318b8c4865"
      },
      "outputs": [],
      "source": [
        "#image_uri = '{0}.dkr.ecr.{1}.amazonaws.com/all-in-one-ai-stable-diffusion-webui-training'.format(account_id, region_name)\n",
        "image_uri = '687912291502.dkr.ecr.ap-southeast-1.amazonaws.com/lora-finetuning:latest'\n",
        "models_s3uri = 's3://{}/stable-diffusion/models/{}/{}'.format(bucket,'lora','model.tar.gz')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "757db6d4-5b2d-486c-8329-0995b21f25cf",
      "metadata": {
        "id": "757db6d4-5b2d-486c-8329-0995b21f25cf"
      },
      "source": [
        "Train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "38dda204-a307-4776-b907-e8e3548df905",
      "metadata": {
        "jupyter": {
          "outputs_hidden": true
        },
        "tags": [],
        "id": "38dda204-a307-4776-b907-e8e3548df905"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "def json_encode_hyperparameters(hyperparameters):\n",
        "    for (k, v) in hyperparameters.items():\n",
        "        print(k, v)\n",
        "\n",
        "    return {k: json.dumps(v) for (k, v) in hyperparameters.items()}\n",
        "\n",
        "instance_type = 'ml.g4dn.xlarge'\n",
        "\n",
        "s3_model_output_location='s3://{}/{}/{}'.format(bucket, 'lora', 'trained_models')\n",
        "base_model_name=\"runwayml/stable-diffusion-v1-5\"\n",
        "output_dir=\"/opt/ml/model/\"\n",
        "#HUB_MODEL_ID=\"pokemon-lora\"\n",
        "dataset_name=\"lambdalabs/pokemon-blip-captions\"\n",
        "\n",
        "environment = {\n",
        "    'PYTORCH_CUDA_ALLOC_CONF':'max_split_size_mb:32',\n",
        "    'LD_LIBRARY_PATH':\"${LD_LIBRARY_PATH}:/opt/conda/lib/\"\n",
        "}\n",
        "\n",
        "hyperparameters = {\n",
        "                    #'model_name':'aws-trained-lora-model',\n",
        "                    'mixed_precision':'fp16',\n",
        "                    'pretrained_model_name_or_path': base_model_name,\n",
        "                    'dataset_name':dataset_name,\n",
        "                    #'train_data_dir':'/opt/ml/input/data/images/',\n",
        "                    'dataloader_num_workers':8,\n",
        "                    'max_grad_norm':1,\n",
        "                    'output_dir':output_dir,\n",
        "                    'checkpointing_steps':1000,\n",
        "                    'validation_prompt':'Totoro',\n",
        "                    'seed':1338,\n",
        "                    'manul_upload_model_path':s3_model_output_location,\n",
        "                    'resolution':512,\n",
        "                    'train_batch_size':1,\n",
        "                    'gradient_accumulation_steps':4,\n",
        "                    'learning_rate':2e-06,\n",
        "                    'lr_scheduler':'cosine',\n",
        "                    'lr_warmup_steps':0,\n",
        "                    'max_train_steps':1000\n",
        "}\n",
        "\n",
        "hyperparameters = json_encode_hyperparameters(hyperparameters)\n",
        "\n",
        "from sagemaker.estimator import Estimator\n",
        "#inputs = {\n",
        "#    'images': images_s3uri,\n",
        "#    'models': models_s3uri\n",
        "#}\n",
        "\n",
        "estimator = Estimator(\n",
        "    role = role,\n",
        "    instance_count=1,\n",
        "    instance_type = instance_type,\n",
        "    image_uri = image_uri,\n",
        "    hyperparameters = hyperparameters,\n",
        "    environment = environment\n",
        ")\n",
        "estimator.fit()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f5edb9ee-39e1-4203-8b79-aa229f9ab453",
      "metadata": {
        "id": "f5edb9ee-39e1-4203-8b79-aa229f9ab453"
      },
      "source": [
        "WEBUI"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a25e7b26-a89f-4733-97ad-3a7a35add288",
      "metadata": {
        "id": "a25e7b26-a89f-4733-97ad-3a7a35add288",
        "outputId": "5bfa4008-2e80-407d-e04c-606877799cc0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                           PRE .ipynb_checkpoints/\n",
            "2023-03-16 02:01:06     262251 00000-0-IMG20230302163943.png\n",
            "2023-03-16 02:01:06        144 00000-0-IMG20230302163943.txt\n",
            "2023-03-16 02:01:06     269277 00001-0-IMG20230302163945.png\n",
            "2023-03-16 02:01:06        116 00001-0-IMG20230302163945.txt\n",
            "2023-03-16 02:01:06     287568 00002-0-IMG20230302163946.png\n",
            "2023-03-16 02:01:06         95 00002-0-IMG20230302163946.txt\n",
            "2023-03-16 02:01:06     289849 00003-0-IMG20230302163947.png\n",
            "2023-03-16 02:01:06        166 00003-0-IMG20230302163947.txt\n",
            "2023-03-16 02:01:06     275408 00004-0-IMG20230302163948.png\n",
            "2023-03-16 02:01:06        189 00004-0-IMG20230302163948.txt\n",
            "2023-03-16 02:01:06     267037 00005-0-IMG20230302163954.png\n",
            "2023-03-16 02:01:06        169 00005-0-IMG20230302163954.txt\n",
            "2023-03-16 02:01:06     296417 00006-0-IMG20230302163956.png\n",
            "2023-03-16 02:01:06        115 00006-0-IMG20230302163956.txt\n",
            "2023-03-16 02:01:06        270 dataset.toml\n"
          ]
        }
      ],
      "source": [
        "#!aws s3 rm --recursive $images_s3uri\n",
        "!aws s3 ls $images_s3uri"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "14d8e6fe-d060-41f7-b00c-1d9d7f620424",
      "metadata": {
        "tags": [],
        "id": "14d8e6fe-d060-41f7-b00c-1d9d7f620424",
        "outputId": "5b13f5b2-2892-427e-cb67-f1d3cbea1ceb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "mixed_precision fp16\n",
            "pretrained_model_name_or_path runwayml/stable-diffusion-v1-5\n",
            "dataset_config /opt/ml/input/data/images/dataset.toml\n",
            "output_dir /opt/ml/model/\n",
            "output_name aws-trained-lora-model\n",
            "save_model_as safetensors\n",
            "prior_loss_weight 1.0\n",
            "max_train_steps 400\n",
            "learning_rate 0.0001\n",
            "optimizer_type AdamW8bit\n",
            "xformers True\n",
            "cache_latents True\n",
            "gradient_checkpointing True\n",
            "save_every_n_epochs 100\n",
            "network_module networks.lora\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:sagemaker:Creating training-job with name: lora-finetuning-v2-2023-03-16-02-53-40-698\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2023-03-16 02:53:41 Starting - Starting the training job...\n",
            "2023-03-16 02:53:58 Starting - Preparing the instances for training......\n",
            "2023-03-16 02:55:08 Downloading - Downloading input data\n",
            "2023-03-16 02:55:08 Training - Downloading the training image..............."
          ]
        }
      ],
      "source": [
        "import json\n",
        "def json_encode_hyperparameters(hyperparameters):\n",
        "    for (k, v) in hyperparameters.items():\n",
        "        print(k, v)\n",
        "\n",
        "    return {k: json.dumps(v) for (k, v) in hyperparameters.items()}\n",
        "\n",
        "images_s3uri = 's3://{0}/dreambooth/images/'.format(bucket)\n",
        "image_uri = '687912291502.dkr.ecr.ap-southeast-1.amazonaws.com/lora-finetuning-v2:latest'\n",
        "base_model_name=\"runwayml/stable-diffusion-v1-5\"\n",
        "output_dir=\"/opt/ml/model/\"\n",
        "instance_type = 'ml.g4dn.xlarge'\n",
        "\n",
        "environment = {\n",
        "    'PYTORCH_CUDA_ALLOC_CONF':'max_split_size_mb:32',\n",
        "    'LD_LIBRARY_PATH':\"${LD_LIBRARY_PATH}:/opt/conda/lib/\"\n",
        "}\n",
        "\n",
        "hyperparameters = {\n",
        "                    'mixed_precision':'fp16',\n",
        "                    'pretrained_model_name_or_path': base_model_name,\n",
        "                    'dataset_config':'/opt/ml/input/data/images/dataset.toml',\n",
        "                    'output_dir':output_dir,\n",
        "                    'output_name':'aws-trained-lora-model',\n",
        "                    'save_model_as':'safetensors',\n",
        "                    'prior_loss_weight':1.0,\n",
        "                    'max_train_steps':400,\n",
        "                    'learning_rate':1e-4,\n",
        "                    'optimizer_type':\"AdamW8bit\",\n",
        "                    'xformers':True,\n",
        "                    'mixed_precision':\"fp16\",\n",
        "                    'cache_latents':True,\n",
        "                    'gradient_checkpointing':True,\n",
        "                    'save_every_n_epochs':100,\n",
        "                    'network_module':'networks.lora'\n",
        "\n",
        "}\n",
        "\n",
        "hyperparameters = json_encode_hyperparameters(hyperparameters)\n",
        "\n",
        "from sagemaker.estimator import Estimator\n",
        "inputs = {\n",
        "    'images': images_s3uri\n",
        "}\n",
        "\n",
        "estimator = Estimator(\n",
        "    role = role,\n",
        "    instance_count=1,\n",
        "    instance_type = instance_type,\n",
        "    image_uri = image_uri,\n",
        "    hyperparameters = hyperparameters,\n",
        "    environment = environment\n",
        ")\n",
        "estimator.fit(inputs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bd181b4e-f435-4dca-842a-444d083fdf3c",
      "metadata": {
        "tags": [],
        "id": "bd181b4e-f435-4dca-842a-444d083fdf3c",
        "outputId": "79aa5bec-d1d2-4869-e6f3-2d55f0880b75"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model artifact saved at:\n",
            " s3://sagemaker-ap-southeast-1-687912291502/lora-finetuning-2023-03-06-14-44-55-604/output/model.tar.gz\n"
          ]
        }
      ],
      "source": [
        "lora_model_data = estimator.model_data\n",
        "print(\"Model artifact saved at:\\n\", lora_model_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "21b90beb-3b46-479d-a933-9540b0723331",
      "metadata": {
        "tags": [],
        "id": "21b90beb-3b46-479d-a933-9540b0723331",
        "outputId": "d637f46f-08db-455e-e47c-790551b4761c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2023-03-06 15:28:25   20.2 MiB model.tar.gz\n",
            "\n",
            "Total Objects: 1\n",
            "   Total Size: 20.2 MiB\n"
          ]
        }
      ],
      "source": [
        "!aws s3 ls --human-readable --summarize s3://sagemaker-ap-southeast-1-687912291502/lora-finetuning-2023-03-06-14-44-55-604/output/model.tar.gz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "732a1f68-b1cd-45a2-9ffd-8fd0c8bc4ee8",
      "metadata": {
        "id": "732a1f68-b1cd-45a2-9ffd-8fd0c8bc4ee8",
        "outputId": "4abd60bc-34b9-423f-91db-d53342538111"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "checkpoint-1000/\n",
            "checkpoint-1000/pytorch_model.bin\n",
            "checkpoint-1000/random_states_0.pkl\n",
            "checkpoint-1000/optimizer.bin\n",
            "checkpoint-1000/scheduler.bin\n",
            "checkpoint-1000/scaler.pt\n",
            "pytorch_lora_weights.bin\n",
            "logs/\n",
            "logs/text2image-fine-tune/\n",
            "logs/text2image-fine-tune/1678114320.4189239/\n",
            "logs/text2image-fine-tune/1678114320.4189239/events.out.tfevents.1678114320.ip-10-0-166-10.ap-southeast-1.compute.internal.23.1\n",
            "logs/text2image-fine-tune/events.out.tfevents.1678114320.ip-10-0-166-10.ap-southeast-1.compute.internal.23.0\n",
            "logs/text2image-fine-tune/1678114320.4203773/\n",
            "logs/text2image-fine-tune/1678114320.4203773/hparams.yml\n"
          ]
        }
      ],
      "source": [
        "!tar -xvf ./model.tar.gz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "054c55c1-08d5-4c3c-ab5f-79906ef93027",
      "metadata": {
        "id": "054c55c1-08d5-4c3c-ab5f-79906ef93027"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "instance_type": "ml.m5.large",
    "kernelspec": {
      "display_name": "Python 3 (Data Science)",
      "language": "python",
      "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:ap-southeast-1:492261229750:image/datascience-1.0"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.10"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}